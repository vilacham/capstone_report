{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning to Predict NBA Games Winners\n",
    "\n",
    "This jupyter notebook is an auxiliar material to my capstone project report in the Udacity's Machine Learning Engineer Nanodegree. The PDF file can be found in my GitHub repository:\n",
    "\n",
    "* https://github.com/vilacham/capstone_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importing data\n",
    "\n",
    "As a first step, I will import the dataset and create a copy of it to work on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was successfully imported and has 36154 samples with 96 features each.\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import dataset and create a copy of it\n",
    "try:\n",
    "    original_data = pd.read_excel('capstone_database.xlsx')\n",
    "    data = original_data\n",
    "    print('Dataset was successfully imported and has {} samples with {} features each.'.format(*data.shape))\n",
    "except:\n",
    "    print('Dataset could not be loaded. Is it missing?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data preprocessing\n",
    "\n",
    "Now that I have a copy of the dataset, my next steps are: \n",
    "* rename its columns;\n",
    "* remove NaNs;\n",
    "* deal with categorical data;\n",
    "* create the label column; and\n",
    "* drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functions import preprocess\n",
    "data = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58229942100909848"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from best_streak_classifier import BestStreakClassifier\n",
    "bsc = BestStreakClassifier(data['H STK'], data['A STK'])\n",
    "bsc.score(data['WINNER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename data columns\n",
    "data.columns = ['DATE', 'A TEAM', 'H TEAM', 'osite', 'A PTS', 'H PTS', 'A STK', 'H STK', 'A PTS LG', 'A FGM LG', 'A FGA LG', \n",
    "                'A 3PM LG', 'A 3PA LG', 'A FTM LG', 'A FTA LG', 'A OREB LG', 'A DREB LG', 'A REB LG', 'A AST LG', 'A TOV LG', \n",
    "                'A STL LG', 'A BLK LG', 'H PTS LG', 'H FGM LG', 'H FGA LG', 'H 3PM LG', 'H 3PA LG', 'H FTM LG', 'H FTA LG', \n",
    "                'H OREB LG', 'H DREB LG', 'H REB LG', 'H AST LG', 'H TOV LG', 'H STL LG', 'H BLK LG', 'A PTS L2G', 'A FGM L2G', \n",
    "                'A FGA L2G', 'A 3PM L2G', 'A 3PA L2G', 'A FTM L2G', 'A FTA L2G', 'A OREB L2G', 'A DREB L2G', 'A REB L2G', \n",
    "                'A AST L2G', 'A TOV L2G', 'A STL L2G', 'A BLK L2G', 'H PTS L2G', 'H FGM L2G', 'H FGA L2G', 'H 3PM L2G', \n",
    "                'H 3PA L2G', 'H FTM L2G', 'H FTA L2G', 'H OREB L2G', 'H DREB L2G', 'H REB L2G', 'H AST L2G', 'H TOV L2G', \n",
    "                'H STL L2G', 'H BLK L2G', 'A PTS L5G', 'A FGM L5G', 'A FGA L5G', 'A 3PM L5G', 'A 3PA L5G', 'A FTM L5G', \n",
    "                'A FTA L5G', 'A OREB L5G', 'A DREB L5G', 'A REB L5G', 'A AST L5G', 'A TOV L5G', 'A STL L5G', 'A BLK L5G', \n",
    "                'H PTS L5G', 'H FGM L5G', 'H FGA L5G', 'H 3PM L5G', 'H 3PA L5G', 'H FTM L5G', 'H FTA L5G', 'H OREB L5G', \n",
    "                'H DREB L5G', 'H REB L5G', 'H AST L5G', 'H TOV L5G', 'H STL L5G', 'H BLK L5G', 'OVT', 'DAY', 'MTH', 'PLAYOFFS']\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Replace '-' and 'away' by NaN values and then replace it\n",
    "data.replace(to_replace='-', value=np.nan, inplace=True, regex=True)\n",
    "data.replace(to_replace='away', value=np.nan, inplace=True, regex=True)\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# Deal with 'DAY' and 'MTH' columns\n",
    "data = pd.get_dummies(data, columns=['DAY', 'MTH'])\n",
    "\n",
    "# Create label column (1 for home team win, 0 for visitor win)\n",
    "data['WINNER'] = (data['H PTS'] > data['A PTS']).astype(int)\n",
    "\n",
    "# Drop unecesary columns\n",
    "columns_to_drop = ['index', 'DATE', 'A TEAM', 'H TEAM', 'osite', 'A PTS', 'H PTS']\n",
    "data.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58229942100909848"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ USAR ESSA CÉLULA\n",
    "from best_streak_classifier import BestStreakClassifier\n",
    "bsc = BestStreakClassifier(data['H STK'], data['A STK'])\n",
    "bsc.score(data['WINNER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9856\n",
      "16926\n",
      "0.582299421009\n"
     ]
    }
   ],
   "source": [
    "############################ DELETAR ESSA CÉLULA\n",
    "data['STR_WINNER'] = (data['H STK'] >= data['A STK']).astype(int)\n",
    "data['CORRECT_STR_WINNER'] = (data['WINNER'] == data['STR_WINNER']).astype(int)\n",
    "print(data['CORRECT_STR_WINNER'].sum())\n",
    "print(len(data['CORRECT_STR_WINNER']))\n",
    "print(data['CORRECT_STR_WINNER'].sum() / len(data['CORRECT_STR_WINNER']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have only te features that I want in my dataset, I will make sure all of them are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert all features to numerical\n",
    "data = data.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3214 outliers for more than one feature.\n",
      "Original data had 16926 samples.\n",
      "Good data has 13712 samples.\n"
     ]
    }
   ],
   "source": [
    "from functions import get_frequent_outliers\n",
    "outliers = get_frequent_outliers(data)\n",
    "good_data = data.drop(data.index[outliers]).reset_index(drop=True)\n",
    "print('{} outliers for more than one feature.'.format(len(outliers)))\n",
    "print('Original data had {} samples.'.format(data.shape[0]))\n",
    "print('Good data has {} samples.'.format(good_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3214 outliers for more than one feature.\n",
      "Original data had 16926 samples.\n",
      "New data has 13712 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import counter\n",
    "from collections import Counter\n",
    "\n",
    "# Drop outliers\n",
    "counter = Counter()\n",
    "for feature in data.iloc[:, 2:87].columns:\n",
    "    quartile_1 = np.percentile(data[feature], 25)\n",
    "    quartile_3 = np.percentile(data[feature], 75)\n",
    "    step = (quartile_3 - quartile_1) * 1.5\n",
    "    outliers = data[~((data[feature] >= quartile_1 - step) & (data[feature] <= quartile_3 + step))]\n",
    "    # print('{} outliers for the feature {}.'.format(len(outliers), feature))\n",
    "    counter.update(outliers.index.values)\n",
    "frequent_outliers = [outlier[0] for outlier in counter.items() if outlier[1] > 1]\n",
    "print('{} outliers for more than one feature.'.format(len(frequent_outliers)))\n",
    "good_data = data.drop(data.index[frequent_outliers]).reset_index(drop = True)\n",
    "print(\"Original data had {} samples.\".format(data.shape[0]))\n",
    "print(\"New data has {} samples.\".format(good_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define columns to standardize\n",
    "columns_to_standardize = ['A PTS LG', 'A FGM LG', 'A FGA LG', 'A 3PM LG', 'A 3PA LG', 'A FTM LG', 'A FTA LG', 'A OREB LG', \n",
    "                          'A DREB LG', 'A REB LG', 'A AST LG', 'A TOV LG', 'A STL LG', 'A BLK LG', 'H PTS LG', 'H FGM LG', \n",
    "                          'H FGA LG', 'H 3PM LG', 'H 3PA LG', 'H FTM LG', 'H FTA LG', 'H OREB LG', 'H DREB LG', 'H REB LG', \n",
    "                          'H AST LG', 'H TOV LG', 'H STL LG', 'H BLK LG', 'A PTS L2G', 'A FGM L2G', 'A FGA L2G', 'A 3PM L2G', \n",
    "                          'A 3PA L2G', 'A FTM L2G', 'A FTA L2G', 'A OREB L2G', 'A DREB L2G', 'A REB L2G', 'A AST L2G', \n",
    "                          'A TOV L2G', 'A STL L2G', 'A BLK L2G', 'H PTS L2G', 'H FGM L2G', 'H FGA L2G', 'H 3PM L2G', \n",
    "                          'H 3PA L2G', 'H FTM L2G', 'H FTA L2G', 'H OREB L2G', 'H DREB L2G', 'H REB L2G', 'H AST L2G', \n",
    "                          'H TOV L2G', 'H STL L2G', 'H BLK L2G', 'A PTS L5G', 'A FGM L5G', 'A FGA L5G', 'A 3PM L5G', \n",
    "                          'A 3PA L5G', 'A FTM L5G', 'A FTA L5G', 'A OREB L5G', 'A DREB L5G', 'A REB L5G', 'A AST L5G', \n",
    "                          'A TOV L5G', 'A STL L5G', 'A BLK L5G', 'H PTS L5G', 'H FGM L5G', 'H FGA L5G', 'H 3PM L5G', \n",
    "                          'H 3PA L5G', 'H FTM L5G', 'H FTA L5G', 'H OREB L5G', 'H DREB L5G', 'H REB L5G', 'H AST L5G', \n",
    "                          'H TOV L5G', 'H STL L5G', 'H BLK L5G', 'OVT']\n",
    "\n",
    "# Create scaler object\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Avoid pandas warning\n",
    "pd.options.mode.chained_assignment = None # default='warn'\n",
    "\n",
    "# Standardize training and testing datasets\n",
    "X_train.loc[:, columns_to_standardize] = standard_scaler.fit_transform(X_train[columns_to_standardize])\n",
    "X_test.loc[:, columns_to_standardize] = standard_scaler.transform(X_test[columns_to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide training set and get last game data\n",
    "X_train_last_game = X_train[list(X_train.columns[:30]) + list(X_train.columns[86:])]\n",
    "X_test_last_game = X_test[list(X_test.columns[:30]) + list(X_test.columns[86:])]\n",
    "\n",
    "# Divide training set and get last two games data\n",
    "X_train_last_two_games = X_train[list(X_train.columns[:2]) + list(X_train.columns[30:58]) + list(X_train.columns[86:])]\n",
    "X_test_last_two_games = X_test[list(X_test.columns[:2]) + list(X_test.columns[30:58]) + list(X_test.columns[86:])]\n",
    "\n",
    "# Divide training set and get last five games data\n",
    "X_train_last_five_games = X_train[list(X_train.columns[:2]) + list(X_train.columns[58:])]\n",
    "X_test_last_five_games = X_test[list(X_test.columns[:2]) + list(X_test.columns[58:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Last game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functions import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11848, 49)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17fe7731cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: 8\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce dimensionality of the last game data\n",
    "pca = PCA(n_components=None)\n",
    "X_train_last_game_pca = pca.fit_transform(X_train_last_game)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_exp = np.cumsum(explained_variance_ratio)\n",
    "aux = 0\n",
    "n_comp = 0\n",
    "for i in range(len(cumulative_exp)):\n",
    "    aux = cumulative_exp[i]\n",
    "    if aux > 0.7:\n",
    "        n_comp = i + 1\n",
    "        break\n",
    "\n",
    "print(X_train_last_game.shape)\n",
    "\n",
    "plt.clf()\n",
    "plt.bar(range(X_train_last_game.shape[1]), explained_variance_ratio, alpha=0.5, align='center', label='individual explained variance')\n",
    "plt.step(range(X_train_last_game.shape[1]), cumulative_exp, where='mid', label='cumulative explained variance')\n",
    "plt.plot(list(i for i in range(X_train_last_game.shape[1])), list(0.7 for i in range(X_train_last_game.shape[1])), '--', color='g')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "print('Number of components: {}'.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
