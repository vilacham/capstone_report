{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning to Predict NBA Games Winners\n",
    "\n",
    "This jupyter notebook is an auxiliar material to my capstone project report in the Udacity's Machine Learning Engineer Nanodegree. The PDF file can be found in my GitHub repository:\n",
    "\n",
    "* https://github.com/vilacham/capstone_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importing data\n",
    "\n",
    "As a first step, I will import the dataset and create a copy of it to work on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was successfully imported and has 36154 samples with 96 features each.\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import dataset and create a copy of it\n",
    "try:\n",
    "    original_data = pd.read_excel('capstone_database.xlsx')\n",
    "    data = original_data\n",
    "    print('Dataset was successfully imported and has {} samples with {} features each.'.format(*data.shape))\n",
    "except:\n",
    "    print('Dataset could not be loaded. Is it missing?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importing functions and modules\n",
    "In order to make the reading of this jupyter notebook easier, I opted for writing functions and modules with more extense line codes in separated Python files: `functions.py`, `best_streak_classifier` and `majority_vote_classifier`.\n",
    "\n",
    "The first file, `functions.py`, can be found in https://github.com/vilacham/capstone_report/blob/master/functions.py and contains the following functions:\n",
    "* `preprocess`, which I will use to preprocess data (rename its columns, drop NaNs, deal with categorical data, create label column, drop unnecessary columns and convert all features to numerical data);\n",
    "* `get_frequent_outliers`, which I will use to identify and drop samples that are outliers for more than one feature;\n",
    "* `standardize`, which I will use to normalize features in my dataset;\n",
    "* `divide_data`, which I will use to divide my dataset in three (last game data, last two games data and last five games data);\n",
    "* `get_n_principal_components`, which I will use to find the *n* principal components to reduce my dataset (I aim to use those principal components that explain at least 60% of the variance);\n",
    "* `plot_pca_graph`, which I will use to ploat a graph with the explained variance ratios of the principal components and the cumulative sum of these;\n",
    "* `reduce`, which will reduce my dataset.\n",
    "\n",
    "The second file, `best_streak_classifier.py`, can be found in https://github.com/vilacham/capstone_report/blob/master/best_streak_classifier.py and is a class that contains code to predict a winner based only on the streak features of the home team and the visitor team: the team with the highest streak wins is predicted as the winner, and in the case of tie, the home team is predicted as the winner.\n",
    "\n",
    "The third file, `majority_vote_classifier.py`, can be found in https://github.com/vilacham/capstone_report/blob/master/majority_vote_classifier.py and is a class that contains code to predict a winner based on the majority vote of the following classifiers:\n",
    "* Logistic Regression;\n",
    "* Decision Tree;\n",
    "* K Neighbors;\n",
    "* Multi-Layer Perceptron;\n",
    "* Support Vector Machine;\n",
    "* Gaussian NB;\n",
    "* Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functions as f\n",
    "from best_streak_classifier import BestStreakClassifier\n",
    "from majority_vote_classifier import MajorityVoteClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data preprocessing\n",
    "\n",
    "Now that I have a copy of the dataset, my next steps are: \n",
    "* rename its columns;\n",
    "* remove NaNs;\n",
    "* deal with categorical data;\n",
    "* create the label column; and\n",
    "* drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = f.preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58229942100909848"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################## REVIEW CODE\n",
    "bsc = BestStreakClassifier(data['H STK'], data['A STK'])\n",
    "bsc.score(data['WINNER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3214 outliers for more than one feature.\n",
      "Original data had 16926 samples.\n",
      "Good data has 13712 samples.\n"
     ]
    }
   ],
   "source": [
    "outliers = f.get_frequent_outliers(data)\n",
    "good_data = data.drop(data.index[outliers]).reset_index(drop=True)\n",
    "print('{} outliers for more than one feature.'.format(len(outliers)))\n",
    "print('Original data had {} samples.'.format(data.shape[0]))\n",
    "print('Good data has {} samples.'.format(good_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset\n",
    "X, y = good_data.iloc[:, :-1], good_data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = f.standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide training set and get last game data\n",
    "X_train_last_game = X_train[list(X_train.columns[:30]) + list(X_train.columns[86:])]\n",
    "X_test_last_game = X_test[list(X_test.columns[:30]) + list(X_test.columns[86:])]\n",
    "\n",
    "# Divide training set and get last two games data\n",
    "X_train_last_two_games = X_train[list(X_train.columns[:2]) + list(X_train.columns[30:58]) + list(X_train.columns[86:])]\n",
    "X_test_last_two_games = X_test[list(X_test.columns[:2]) + list(X_test.columns[30:58]) + list(X_test.columns[86:])]\n",
    "\n",
    "# Divide training set and get last five games data\n",
    "X_train_last_five_games = X_train[list(X_train.columns[:2]) + list(X_train.columns[58:])]\n",
    "X_test_last_five_games = X_test[list(X_test.columns[:2]) + list(X_test.columns[58:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Last game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: 6\n"
     ]
    }
   ],
   "source": [
    "n_comp = f.get_n_principal_components(X_train_last_game)\n",
    "print('Number of components: {}'.format(n_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_reduced, X_test_reduced = f.reduce(X_train_last_game, X_test_last_game, n_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Streak Classifier score in last game dataset: 0.5822046259637425\n"
     ]
    }
   ],
   "source": [
    "################################ Fazer por Ãºltimo\n",
    "bsc_last_game = BestStreakClassifier(X_train_last_game['H STK'].values, X_train_last_game['A STK'].values)\n",
    "bsc_pred_train = bsc_last_game.predict()\n",
    "print('Best Streak Classifier score in last game dataset: {}'.format(bsc_last_game.score(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression score in the training set: 0.612%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_last_game = LogisticRegression()\n",
    "lr_last_game.fit(X_train_reduced, y_train)\n",
    "train_score = lr_last_game.score(X_train_reduced, y_train)\n",
    "print('Logistic regression score in the training set: {:.3f}%'.format(train_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Last two games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: 6\n"
     ]
    }
   ],
   "source": [
    "n_comp_last_two_games = f.get_n_principal_components(X_train_last_two_games)\n",
    "print('Number of components: {}'.format(n_comp_last_two_games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_last_two_games_reduced, X_test_last_two_games_reduced = f.reduce(X_train_last_two_games, X_test_last_two_games, n_comp_last_two_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression score in the training set: 0.614%\n"
     ]
    }
   ],
   "source": [
    "lr_last_two_games = LogisticRegression()\n",
    "lr_last_two_games.fit(X_train_last_two_games_reduced, y_train)\n",
    "train_score_last_two_games = lr_last_two_games.score(X_train_last_two_games_reduced, y_train)\n",
    "print('Logistic regression score in the training set: {:.3f}%'.format(train_score_last_two_games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier score in the training set: 0.6263804959366535\n"
     ]
    }
   ],
   "source": [
    "adaboost_last_two_games = AdaBoostClassifier()\n",
    "adaboost_last_two_games.fit(X_train_last_two_games_reduced, y_train)\n",
    "ada_score_l2g = adaboost_last_two_games.score(X_train_last_two_games_reduced, y_train)\n",
    "print('AdaBoost Classifier score in the training set: {}'.format(ada_score_l2g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Last five games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: 6\n"
     ]
    }
   ],
   "source": [
    "n_comp_last_five_games = f.get_n_principal_components(X_train_last_five_games)\n",
    "print('Number of components: {}'.format(n_comp_last_five_games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_last_five_games_reduced, X_test_last_five_games_reduced = f.reduce(X_train_last_five_games, X_test_last_five_games, n_comp_last_five_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression score in the training set: 0.614\n"
     ]
    }
   ],
   "source": [
    "lr_last_five_games = LogisticRegression()\n",
    "lr_last_five_games.fit(X_train_last_five_games_reduced, y_train)\n",
    "train_score_last_five_games = lr_last_five_games.score(X_train_last_five_games_reduced, y_train)\n",
    "print('Logistic regression score in the training set: {:.3f}'.format(train_score_last_five_games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier score in the training set: 0.6236715982496354\n",
      "AdaBoost Classifier score in the testing set: 0.6098687408847837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=1, random_state=42)\n",
    "adaboost_last_five_games = AdaBoostClassifier(base_estimator=tree, n_estimators=500, learning_rate=0.1, random_state=42)\n",
    "adaboost_last_five_games.fit(X_train_last_five_games_reduced, y_train)\n",
    "ada_score_l5g = adaboost_last_five_games.score(X_train_last_five_games_reduced, y_train)\n",
    "ada_test_score_l5g = adaboost_last_five_games.score(X_test_last_five_games_reduced, y_test)\n",
    "print('AdaBoost Classifier score in the training set: {}'.format(ada_score_l5g))\n",
    "print('AdaBoost Classifier score in the testing set: {}'.format(ada_test_score_l5g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
