{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning to Predict NBA Games Winners\n",
    "\n",
    "This jupyter notebook is an auxiliar material to my capstone project report in the Udacity's Machine Learning Engineer Nanodegree. The PDF file can be found in my GitHub repository:\n",
    "\n",
    "* https://github.com/vilacham/capstone_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importing data\n",
    "\n",
    "As a first step, I will import the dataset and create a copy of it to work on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was successfully imported and has 36154 samples with 96 features each.\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import dataset and create a copy of it\n",
    "try:\n",
    "    original_data = pd.read_excel('capstone_database.xlsx')\n",
    "    data = original_data\n",
    "    print('Dataset was successfully imported and has {} samples with {} features each.'.format(*data.shape))\n",
    "except:\n",
    "    print('Dataset could not be loaded. Is it missing?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data preprocessing\n",
    "\n",
    "Now that I have a copy of the dataset, my next steps are: \n",
    "* rename its columns;\n",
    "* remove NaNs;\n",
    "* deal with categorical data;\n",
    "* create the label column; and\n",
    "* drop unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename data columns\n",
    "data.columns = ['DATE', 'A TEAM', 'H TEAM', 'osite', 'A PTS', 'H PTS', 'A STK', 'H STK', 'A PTS LG', 'A FGM LG', 'A FGA LG', \n",
    "                'A 3PM LG', 'A 3PA LG', 'A FTM LG', 'A FTA LG', 'A OREB LG', 'A DREB LG', 'A REB LG', 'A AST LG', 'A TOV LG', \n",
    "                'A STL LG', 'A BLK LG', 'H PTS LG', 'H FGM LG', 'H FGA LG', 'H 3PM LG', 'H 3PA LG', 'H FTM LG', 'H FTA LG', \n",
    "                'H OREB LG', 'H DREB LG', 'H REB LG', 'H AST LG', 'H TOV LG', 'H STL LG', 'H BLK LG', 'A PTS L2G', 'A FGM L2G', \n",
    "                'A FGA L2G', 'A 3PM L2G', 'A 3PA L2G', 'A FTM L2G', 'A FTA L2G', 'A OREB L2G', 'A DREB L2G', 'A REB L2G', \n",
    "                'A AST L2G', 'A TOV L2G', 'A STL L2G', 'A BLK L2G', 'H PTS L2G', 'H FGM L2G', 'H FGA L2G', 'H 3PM L2G', \n",
    "                'H 3PA L2G', 'H FTM L2G', 'H FTA L2G', 'H OREB L2G', 'H DREB L2G', 'H REB L2G', 'H AST L2G', 'H TOV L2G', \n",
    "                'H STL L2G', 'H BLK L2G', 'A PTS L5G', 'A FGM L5G', 'A FGA L5G', 'A 3PM L5G', 'A 3PA L5G', 'A FTM L5G', \n",
    "                'A FTA L5G', 'A OREB L5G', 'A DREB L5G', 'A REB L5G', 'A AST L5G', 'A TOV L5G', 'A STL L5G', 'A BLK L5G', \n",
    "                'H PTS L5G', 'H FGM L5G', 'H FGA L5G', 'H 3PM L5G', 'H 3PA L5G', 'H FTM L5G', 'H FTA L5G', 'H OREB L5G', \n",
    "                'H DREB L5G', 'H REB L5G', 'H AST L5G', 'H TOV L5G', 'H STL L5G', 'H BLK L5G', 'OVT', 'DAY', 'MTH', 'PLAYOFFS']\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Replace '-' and 'away' by NaN values and then replace it\n",
    "data.replace(to_replace='-', value=np.nan, inplace=True, regex=True)\n",
    "data.replace(to_replace='away', value=np.nan, inplace=True, regex=True)\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# Deal with 'DAY' and 'MTH' columns\n",
    "data = pd.get_dummies(data, columns=['DAY', 'MTH'])\n",
    "\n",
    "# Create label column (1 for home team win, 0 for visitor win)\n",
    "data['WINNER'] = (data['H PTS'] > data['A PTS']).astype(int)\n",
    "\n",
    "# Drop unecesary columns\n",
    "columns_to_drop = ['index', 'DATE', 'A TEAM', 'H TEAM', 'osite', 'A PTS', 'H PTS']\n",
    "data.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have only te features that I want in my dataset, I will make sure all of them are numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert all features to numerical\n",
    "data = data.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 outliers for the feature A PTS LG.\n",
      "127 outliers for the feature A FGM LG.\n",
      "157 outliers for the feature A FGA LG.\n",
      "90 outliers for the feature A 3PM LG.\n",
      "116 outliers for the feature A 3PA LG.\n",
      "200 outliers for the feature A FTM LG.\n",
      "185 outliers for the feature A FTA LG.\n",
      "71 outliers for the feature A OREB LG.\n",
      "147 outliers for the feature A DREB LG.\n",
      "124 outliers for the feature A REB LG.\n",
      "115 outliers for the feature A AST LG.\n",
      "203 outliers for the feature A TOV LG.\n",
      "584 outliers for the feature A STL LG.\n",
      "461 outliers for the feature A BLK LG.\n",
      "107 outliers for the feature H PTS LG.\n",
      "121 outliers for the feature H FGM LG.\n",
      "141 outliers for the feature H FGA LG.\n",
      "93 outliers for the feature H 3PM LG.\n",
      "127 outliers for the feature H 3PA LG.\n",
      "173 outliers for the feature H FTM LG.\n",
      "152 outliers for the feature H FTA LG.\n",
      "62 outliers for the feature H OREB LG.\n",
      "136 outliers for the feature H DREB LG.\n",
      "210 outliers for the feature H REB LG.\n",
      "103 outliers for the feature H AST LG.\n",
      "172 outliers for the feature H TOV LG.\n",
      "118 outliers for the feature H STL LG.\n",
      "452 outliers for the feature H BLK LG.\n",
      "112 outliers for the feature A PTS L2G.\n",
      "99 outliers for the feature A FGM L2G.\n",
      "172 outliers for the feature A FGA L2G.\n",
      "74 outliers for the feature A 3PM L2G.\n",
      "167 outliers for the feature A 3PA L2G.\n",
      "126 outliers for the feature A FTM L2G.\n",
      "192 outliers for the feature A FTA L2G.\n",
      "137 outliers for the feature A OREB L2G.\n",
      "84 outliers for the feature A DREB L2G.\n",
      "201 outliers for the feature A REB L2G.\n",
      "150 outliers for the feature A AST L2G.\n",
      "243 outliers for the feature A TOV L2G.\n",
      "95 outliers for the feature A STL L2G.\n",
      "212 outliers for the feature A BLK L2G.\n",
      "152 outliers for the feature H PTS L2G.\n",
      "81 outliers for the feature H FGM L2G.\n",
      "114 outliers for the feature H FGA L2G.\n",
      "61 outliers for the feature H 3PM L2G.\n",
      "195 outliers for the feature H 3PA L2G.\n",
      "116 outliers for the feature H FTM L2G.\n",
      "191 outliers for the feature H FTA L2G.\n",
      "123 outliers for the feature H OREB L2G.\n",
      "101 outliers for the feature H DREB L2G.\n",
      "131 outliers for the feature H REB L2G.\n",
      "95 outliers for the feature H AST L2G.\n",
      "243 outliers for the feature H TOV L2G.\n",
      "78 outliers for the feature H STL L2G.\n",
      "221 outliers for the feature H BLK L2G.\n",
      "161 outliers for the feature A PTS L5G.\n",
      "189 outliers for the feature A FGM L5G.\n",
      "88 outliers for the feature A FGA L5G.\n",
      "142 outliers for the feature A 3PM L5G.\n",
      "121 outliers for the feature A 3PA L5G.\n",
      "129 outliers for the feature A FTM L5G.\n",
      "135 outliers for the feature A FTA L5G.\n",
      "187 outliers for the feature A OREB L5G.\n",
      "118 outliers for the feature A DREB L5G.\n",
      "176 outliers for the feature A REB L5G.\n",
      "177 outliers for the feature A AST L5G.\n",
      "100 outliers for the feature A TOV L5G.\n",
      "98 outliers for the feature A STL L5G.\n",
      "100 outliers for the feature A BLK L5G.\n",
      "124 outliers for the feature H PTS L5G.\n",
      "155 outliers for the feature H FGM L5G.\n",
      "93 outliers for the feature H FGA L5G.\n",
      "139 outliers for the feature H 3PM L5G.\n",
      "166 outliers for the feature H 3PA L5G.\n",
      "109 outliers for the feature H FTM L5G.\n",
      "129 outliers for the feature H FTA L5G.\n",
      "187 outliers for the feature H OREB L5G.\n",
      "108 outliers for the feature H DREB L5G.\n",
      "120 outliers for the feature H REB L5G.\n",
      "156 outliers for the feature H AST L5G.\n",
      "92 outliers for the feature H TOV L5G.\n",
      "88 outliers for the feature H STL L5G.\n",
      "93 outliers for the feature H BLK L5G.\n",
      "1075 outliers for the feature OVT.\n",
      "3214 outliers for more than one feature.\n",
      "Original data had 16926 samples.\n",
      "New data has 13712 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import counter\n",
    "from collections import Counter\n",
    "\n",
    "# Drop outliers\n",
    "counter = Counter()\n",
    "for feature in data.iloc[:, 2:87].columns:\n",
    "    quartile_1 = np.percentile(data[feature], 25)\n",
    "    quartile_3 = np.percentile(data[feature], 75)\n",
    "    step = (quartile_3 - quartile_1) * 1.5\n",
    "    outliers = data[~((data[feature] >= quartile_1 - step) & (data[feature] <= quartile_3 + step))]\n",
    "    print('{} outliers for the feature {}.'.format(len(outliers), feature))\n",
    "    counter.update(outliers.index.values)\n",
    "frequent_outliers = [outlier[0] for outlier in counter.items() if outlier[1] > 1]\n",
    "print('{} outliers for more than one feature.'.format(len(frequent_outliers)))\n",
    "good_data = data.drop(data.index[frequent_outliers]).reset_index(drop = True)\n",
    "print(\"Original data had {} samples.\".format(data.shape[0]))\n",
    "print(\"New data has {} samples.\".format(good_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset\n",
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define columns to standardize\n",
    "columns_to_standardize = ['A PTS LG', 'A FGM LG', 'A FGA LG', 'A 3PM LG', 'A 3PA LG', 'A FTM LG', 'A FTA LG', 'A OREB LG', \n",
    "                          'A DREB LG', 'A REB LG', 'A AST LG', 'A TOV LG', 'A STL LG', 'A BLK LG', 'H PTS LG', 'H FGM LG', \n",
    "                          'H FGA LG', 'H 3PM LG', 'H 3PA LG', 'H FTM LG', 'H FTA LG', 'H OREB LG', 'H DREB LG', 'H REB LG', \n",
    "                          'H AST LG', 'H TOV LG', 'H STL LG', 'H BLK LG', 'A PTS L2G', 'A FGM L2G', 'A FGA L2G', 'A 3PM L2G', \n",
    "                          'A 3PA L2G', 'A FTM L2G', 'A FTA L2G', 'A OREB L2G', 'A DREB L2G', 'A REB L2G', 'A AST L2G', \n",
    "                          'A TOV L2G', 'A STL L2G', 'A BLK L2G', 'H PTS L2G', 'H FGM L2G', 'H FGA L2G', 'H 3PM L2G', \n",
    "                          'H 3PA L2G', 'H FTM L2G', 'H FTA L2G', 'H OREB L2G', 'H DREB L2G', 'H REB L2G', 'H AST L2G', \n",
    "                          'H TOV L2G', 'H STL L2G', 'H BLK L2G', 'A PTS L5G', 'A FGM L5G', 'A FGA L5G', 'A 3PM L5G', \n",
    "                          'A 3PA L5G', 'A FTM L5G', 'A FTA L5G', 'A OREB L5G', 'A DREB L5G', 'A REB L5G', 'A AST L5G', \n",
    "                          'A TOV L5G', 'A STL L5G', 'A BLK L5G', 'H PTS L5G', 'H FGM L5G', 'H FGA L5G', 'H 3PM L5G', \n",
    "                          'H 3PA L5G', 'H FTM L5G', 'H FTA L5G', 'H OREB L5G', 'H DREB L5G', 'H REB L5G', 'H AST L5G', \n",
    "                          'H TOV L5G', 'H STL L5G', 'H BLK L5G', 'OVT']\n",
    "\n",
    "# Create scaler object\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Avoid pandas warning\n",
    "pd.options.mode.chained_assignment = None # default='warn'\n",
    "\n",
    "# Standardize training and testing datasets\n",
    "X_train.loc[:, columns_to_standardize] = standard_scaler.fit_transform(X_train[columns_to_standardize])\n",
    "X_test.loc[:, columns_to_standardize] = standard_scaler.transform(X_test[columns_to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide training set and get last game data\n",
    "X_train_last_game = X_train[list(X_train.columns[:30]) + list(X_train.columns[86:])]\n",
    "X_test_last_game = X_test[list(X_test.columns[:30]) + list(X_test.columns[86:])]\n",
    "\n",
    "# Divide training set and get last two games data\n",
    "X_train_last_two_games = X_train[list(X_train.columns[:2]) + list(X_train.columns[30:58]) + list(X_train.columns[86:])]\n",
    "X_test_last_two_games = X_test[list(X_test.columns[:2]) + list(X_test.columns[30:58]) + list(X_test.columns[86:])]\n",
    "\n",
    "# Divide training set and get last five games data\n",
    "X_train_last_five_games = X_train[list(X_train.columns[:2]) + list(X_train.columns[58:])]\n",
    "X_test_last_five_games = X_test[list(X_test.columns[:2]) + list(X_test.columns[58:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Last game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1733afaee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: 8\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce dimensionality of the last game data\n",
    "pca = PCA(n_components=None)\n",
    "X_train_last_game_pca = pca.fit_transform(X_train_last_game)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_exp = np.cumsum(explained_variance_ratio)\n",
    "aux = 0\n",
    "n_comp = 0\n",
    "for i in range(len(cumulative_exp)):\n",
    "    aux = cumulative_exp[i]\n",
    "    if aux > 0.7:\n",
    "        n_comp = i + 1\n",
    "        break\n",
    "\n",
    "plt.clf()\n",
    "plt.bar(range(1, 48), explained_variance_ratio, alpha=0.5, align='center', label='individual explained variance')\n",
    "plt.step(range(1, 48), cumulative_exp, where='mid', label='cumulative explained variance')\n",
    "plt.plot(list(i for i in range(1, 48)), list(0.7 for i in range(1, 48)), '--', color='g')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "print('Number of components: {}'.format(i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from capstone_report_functions import get_n_principal_components\n",
    "n_comp = get_n_principal_components(X_train_last_game)\n",
    "print(n_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
